{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy matplotlib gym torch tensorboardX ptan black flake8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vqbj8Qcc8v7s",
        "outputId": "dbffa398-4b30-48fa-80a9-71474267ec5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting ptan\n",
            "  Downloading ptan-0.8.1-py3-none-any.whl.metadata (521 bytes)\n",
            "Collecting black\n",
            "  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flake8\n",
            "  Downloading flake8-7.1.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (4.25.6)\n",
            "Requirement already satisfied: gymnasium>=0.29.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[atari]>=0.29.0->ptan) (1.0.0)\n",
            "Requirement already satisfied: moviepy==1.0.3 in /usr/local/lib/python3.11/dist-packages (from ptan) (1.0.3)\n",
            "Collecting opencv-python==4.10.0.84 (from ptan)\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting torch\n",
            "  Downloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision==0.20.0 (from ptan)\n",
            "  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting pytorch-ignite==0.5.1 (from ptan)\n",
            "  Downloading pytorch_ignite-0.5.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting stable-baselines3==2.3.2 (from ptan)\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan) (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy==1.0.3->ptan) (0.1.10)\n",
            "Collecting gymnasium>=0.29.0 (from gymnasium[atari]>=0.29.0->ptan)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black) (8.1.8)\n",
            "Collecting mypy-extensions>=0.4.3 (from black)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black) (4.3.6)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pycodestyle<2.13.0,>=2.12.0 (from flake8)\n",
            "  Downloading pycodestyle-2.12.1-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8)\n",
            "  Downloading pyflakes-3.2.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.29.0->gymnasium[atari]>=0.29.0->ptan) (0.0.4)\n",
            "INFO: pip is looking at multiple versions of gymnasium[atari] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting shimmy<1.0,>=0.1.0 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]>=0.29.0->ptan)\n",
            "  Downloading Shimmy-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "INFO: pip is looking at multiple versions of gymnasium[classic-control] to determine which version is compatible with other requirements. This could take a while.\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[classic-control]>=0.29.0->ptan) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan) (2025.1.31)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]>=0.29.0->ptan)\n",
            "  Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]>=0.29.0->ptan) (6.5.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ptan-0.8.1-py3-none-any.whl (26 kB)\n",
            "Downloading torch-2.5.0-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_ignite-0.5.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flake8-7.1.2-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading pycodestyle-2.12.1-py2.py3-none-any.whl (31 kB)\n",
            "Downloading pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, pyflakes, pycodestyle, pathspec, opencv-python, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, mccabe, gymnasium, ale-py, shimmy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, flake8, black, nvidia-cusolver-cu12, torch, torchvision, stable-baselines3, pytorch-ignite, ptan\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.11.0.86\n",
            "    Uninstalling opencv-python-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-4.11.0.86\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.0.0\n",
            "    Uninstalling gymnasium-1.0.0:\n",
            "      Successfully uninstalled gymnasium-1.0.0\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.10.1\n",
            "    Uninstalling ale-py-0.10.1:\n",
            "      Successfully uninstalled ale-py-0.10.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.5.0 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ale-py-0.8.1 black-25.1.0 flake8-7.1.2 gymnasium-0.29.1 mccabe-0.7.0 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opencv-python-4.10.0.84 pathspec-0.12.1 ptan-0.8.1 pycodestyle-2.12.1 pyflakes-3.2.0 pytorch-ignite-0.5.1 shimmy-0.2.1 stable-baselines3-2.3.2 tensorboardX-2.6.2.2 torch-2.5.0 torchvision-0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hj5INsVS2hQS"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class SimpleFFDQN(nn.Module):\n",
        "    def __init__(self, obs_len, actions_n):\n",
        "        \"\"\"\n",
        "        Initialize the Simple Feedforward Dueling Deep Q-Network.\n",
        "\n",
        "        Parameters:\n",
        "        obs_len (int): Length of the input observation vector.\n",
        "        actions_n (int): Number of possible actions.\n",
        "\n",
        "        \"\"\"\n",
        "        super(SimpleFFDQN, self).__init__()\n",
        "\n",
        "        # Value stream network\n",
        "        self.fc_val = nn.Sequential(\n",
        "            nn.Linear(obs_len, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "        # Advantage stream network\n",
        "        self.fc_adv = nn.Sequential(\n",
        "            nn.Linear(obs_len, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, actions_n)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the network.\n",
        "\n",
        "        Parameters:\n",
        "        x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "        torch.Tensor: Output tensor containing the estimated Q-values.\n",
        "\n",
        "        \"\"\"\n",
        "        # Compute value and advantage streams\n",
        "        val = self.fc_val(x)\n",
        "        adv = self.fc_adv(x)\n",
        "\n",
        "        # Combine value and advantage streams to produce the final Q-values\n",
        "        # The advantage values are centered by subtracting their mean to improve stability\n",
        "        return val + (adv - adv.mean(dim=1, keepdim=True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import glob\n",
        "import numpy as np\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Prices = collections.namedtuple('Prices', field_names=['open', 'high', 'low', 'close', 'volume'])\n",
        "def bar2rel(df,tolerance):\n",
        "    prev_vals = None\n",
        "    fix_open_price  = True\n",
        "    open, high, low, close, volume = [], [], [], [], []\n",
        "    count_out = 0\n",
        "    count_filter = 0\n",
        "    count_fixed = 0\n",
        "    for row in df.itertuples():\n",
        "        val = (row._3,row._4,row._5,row._6,row._7)\n",
        "        po, ph, pl,pc,pv = val\n",
        "        if fix_open_price and prev_vals is not None:\n",
        "            ppo, pph, ppl, ppc, ppv = prev_vals\n",
        "            if abs(po - ppc) > 1e-8:\n",
        "                count_fixed += 1\n",
        "                po = ppc\n",
        "                pl = min(pl, po)\n",
        "                ph = max(ph, po)\n",
        "                count_out += 1\n",
        "        open.append(po)\n",
        "        close.append(pc)\n",
        "        high.append(ph)\n",
        "        low.append(pl)\n",
        "        volume.append(pv)\n",
        "        prev_vals = val\n",
        "    prices=Prices(open=np.array(open, dtype=np.float32),\n",
        "                  high=np.array(high, dtype=np.float32),\n",
        "                  low=np.array(low, dtype=np.float32),\n",
        "                  close=np.array(close, dtype=np.float32),\n",
        "                  volume=np.array(volume, dtype=np.float32))\n",
        "    return prices_to_relative(prices)\n",
        "\n",
        "def prices_to_relative(prices):\n",
        "    \"\"\"\n",
        "    Convert prices to relative in respect to open price\n",
        "    :param ochl: tuple with open, close, high, low\n",
        "    :return: tuple with open, rel_close, rel_high, rel_low\n",
        "    \"\"\"\n",
        "    assert isinstance(prices, Prices)\n",
        "    rh = (prices.high - prices.open) / prices.open\n",
        "    rl = (prices.low - prices.open) / prices.open\n",
        "    rc = (prices.close - prices.open) / prices.open\n",
        "    return Prices(open=prices.open, high=rh, low=rl, close=rc, volume=prices.volume)\n",
        "\n",
        "def preprocess(path):\n",
        "    df = pd.read_csv(os.path.abspath(train_path))\n",
        "\n",
        "    index = ['<OPEN>', \"<HIGH>\", \"<LOW>\",\"<CLOSE>\",\"<VOL>\"]\n",
        "    df[index] = df[index].astype(float)\n",
        "    df_normalized = (df - df.min()) / (df.max() - df.min())\n",
        "    # Define the tolerance value\n",
        "    tolerance = 1e-8\n",
        "\n",
        "    # Apply the lambda function to check if each value is within the tolerance of the first value\n",
        "    df_normalized.applymap(lambda v: abs(v - df_normalized.iloc[0]) < tolerance)\n",
        "    return bar2rel(df_normalized,tolerance)"
      ],
      "metadata": {
        "id": "Bhi_4NqE3HSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import gym.spaces\n",
        "from gym.utils import seeding\n",
        "from gym.envs.registration import EnvSpec\n",
        "import enum\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "DEFAULT_BARS_COUNT = 10\n",
        "DEFAULT_COMMISSION_PERC = 0.1\n",
        "\n",
        "class Actions(enum.Enum):\n",
        "    Skip = 0\n",
        "    Buy = 1\n",
        "    Close = 2\n",
        "\n",
        "class State:\n",
        "    def __init__(self, bars_count, commission_perc,\n",
        "                 reset_on_close, reward_on_close=True,\n",
        "                 volumes=True):\n",
        "        \"\"\"\n",
        "        Initializes the State object.\n",
        "\n",
        "        Parameters:\n",
        "        - bars_count (int): Number of bars (time periods) in the state representation.\n",
        "        - commission_perc (float): Commission percentage applied to each trade.\n",
        "        - reset_on_close (bool): Whether to reset the environment when a position is closed.\n",
        "        - reward_on_close (bool): Whether to reward the agent immediately when a position is closed.\n",
        "        - volumes (bool): Whether to include volume information in the state representation.\n",
        "        \"\"\"\n",
        "        assert isinstance(bars_count, int)\n",
        "        assert bars_count > 0\n",
        "        assert isinstance(commission_perc, float)\n",
        "        assert commission_perc >= 0.0\n",
        "        assert isinstance(reset_on_close, bool)\n",
        "        assert isinstance(reward_on_close, bool)\n",
        "        self.bars_count = bars_count\n",
        "        self.commission_perc = commission_perc\n",
        "        self.reset_on_close = reset_on_close\n",
        "        self.reward_on_close = reward_on_close\n",
        "        self.volumes = volumes\n",
        "\n",
        "    def reset(self, prices, offset):\n",
        "        \"\"\"\n",
        "        Resets the state with new prices and offset.\n",
        "\n",
        "        Parameters:\n",
        "        - prices (Prices): Named tuple containing open, high, low, close, and volume prices.\n",
        "        - offset (int): Offset index for the starting position in the price data.\n",
        "        \"\"\"\n",
        "        assert isinstance(prices, Prices)\n",
        "        assert offset >= self.bars_count-1\n",
        "        self.have_position = False\n",
        "        self.open_price = 0.0\n",
        "        self._prices = prices\n",
        "        self._offset = offset\n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "        \"\"\"\n",
        "        Returns the shape of the state representation.\n",
        "        \"\"\"\n",
        "        # [h, l, c] * bars + position_flag + rel_profit\n",
        "        if self.volumes:\n",
        "            return 4 * self.bars_count + 1 + 1,\n",
        "        else:\n",
        "            return 3*self.bars_count + 1 + 1,\n",
        "\n",
        "    def encode(self):\n",
        "        \"\"\"\n",
        "        Converts the current state into a numpy array.\n",
        "        \"\"\"\n",
        "        res = np.ndarray(shape=self.shape, dtype=np.float32)\n",
        "        shift = 0\n",
        "        for bar_idx in range(-self.bars_count+1, 1):\n",
        "            ofs = self._offset + bar_idx\n",
        "\n",
        "            res[shift] = self._prices.high[ofs]\n",
        "            shift += 1\n",
        "            res[shift] = self._prices.low[ofs]\n",
        "            shift += 1\n",
        "            res[shift] = self._prices.close[ofs]\n",
        "            shift += 1\n",
        "            if self.volumes:\n",
        "                res[shift] = self._prices.volume[ofs]\n",
        "                shift += 1\n",
        "        res[shift] = float(self.have_position)\n",
        "        shift += 1\n",
        "        if not self.have_position:\n",
        "            res[shift] = 0.0\n",
        "        else:\n",
        "            res[shift] = self._cur_close() / self.open_price - 1.0\n",
        "        return res\n",
        "\n",
        "    def _cur_close(self):\n",
        "        \"\"\"\n",
        "        Calculates the real close price for the current bar.\n",
        "        \"\"\"\n",
        "        open = self._prices.open[self._offset]\n",
        "        rel_close = self._prices.close[self._offset]\n",
        "        return open * (1.0 + rel_close)\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Performs one step in the environment.\n",
        "\n",
        "        Parameters:\n",
        "        - action (Actions): Action taken by the agent.\n",
        "\n",
        "        Returns:\n",
        "        - reward (float): Reward obtained from the action.\n",
        "        - done (bool): Whether the episode is done.\n",
        "        \"\"\"\n",
        "        assert isinstance(action, Actions)\n",
        "        reward = 0.0\n",
        "        done = False\n",
        "        close = self._cur_close()\n",
        "        if action == Actions.Buy and not self.have_position:\n",
        "            self.have_position = True\n",
        "            self.open_price = close\n",
        "            reward -= self.commission_perc\n",
        "        elif action == Actions.Close and self.have_position:\n",
        "            reward -= self.commission_perc\n",
        "            done |= self.reset_on_close\n",
        "            if self.reward_on_close:\n",
        "                reward += 100.0 * (close / self.open_price - 1.0)\n",
        "            self.have_position = False\n",
        "            self.open_price = 0.0\n",
        "\n",
        "        self._offset += 1\n",
        "        prev_close = close\n",
        "        close = self._cur_close()\n",
        "        done |= self._offset >= self._prices.close.shape[0]-1\n",
        "\n",
        "        if self.have_position and not self.reward_on_close:\n",
        "            reward += 100.0 * (close / prev_close - 1.0)\n",
        "\n",
        "        return reward, done"
      ],
      "metadata": {
        "id": "Q8WiJIrZ3Rts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import gym.spaces\n",
        "from gym.utils import seeding\n",
        "from gym.envs.registration import EnvSpec\n",
        "import enum\n",
        "import numpy as np\n",
        "class StocksEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, prices: Prices, bars_count=DEFAULT_BARS_COUNT,\n",
        "                 commission=DEFAULT_COMMISSION_PERC,\n",
        "                 reset_on_close=True, state_1d=False,\n",
        "                 random_ofs_on_reset=True, reward_on_close=False,\n",
        "                 volumes=False):\n",
        "        \"\"\"\n",
        "        Initializes the StocksEnv environment.\n",
        "\n",
        "        Parameters:\n",
        "        - prices (Prices): Named tuple containing open, high, low, close, and volume prices.\n",
        "        - bars_count (int): Number of bars (time periods) in the state representation.\n",
        "        - commission (float): Commission percentage applied to each trade.\n",
        "        - reset_on_close (bool): Whether to reset the environment when a position is closed.\n",
        "        - state_1d (bool): Whether to represent the state in 1D format.\n",
        "        - random_ofs_on_reset (bool): Whether to reset the environment with a random offset.\n",
        "        - reward_on_close (bool): Whether to reward the agent immediately when a position is closed.\n",
        "        - volumes (bool): Whether to include volume information in the state representation.\n",
        "        \"\"\"\n",
        "        self._prices = prices\n",
        "        self._state = State(\n",
        "            bars_count, commission, reset_on_close,\n",
        "            reward_on_close=reward_on_close, volumes=volumes)\n",
        "        self.action_space = gym.spaces.Discrete(n=len(Actions))\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=-np.inf, high=np.inf,\n",
        "            shape=self._state.shape, dtype=np.float32)\n",
        "        self.random_ofs_on_reset = random_ofs_on_reset\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        \"\"\"\n",
        "        Sets the random seed for reproducibility.\n",
        "        \"\"\"\n",
        "        self.np_random, seed1 = seeding.np_random(seed)\n",
        "        seed2 = seeding.hash_seed(seed1 + 1) % 2 ** 31\n",
        "        return [seed1, seed2]\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Resets the environment to its initial state.\n",
        "\n",
        "        Returns:\n",
        "        - observation (np.ndarray): Initial observation/state of the environment.\n",
        "        \"\"\"\n",
        "        prices = self._prices\n",
        "        bar_count = self._state.bars_count\n",
        "        # Check if prices have enough data for the requested bar count\n",
        "        if len(prices) < bar_count:\n",
        "            # Handle the case where prices have insufficient data\n",
        "            return np.zeros(self._state.shape, dtype=np.float32)\n",
        "\n",
        "\n",
        "        self._instrument = self.np_random.choice(\n",
        "            list(self._prices._fields))\n",
        "        if self._instrument is \"open\":\n",
        "            prices = self._prices.open\n",
        "        if self._instrument is \"close\":\n",
        "            prices = self"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vEACJmZ3LTn",
        "outputId": "6c6933f0-f343-446d-dff5-0c70305ddf25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "<>:63: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:65: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:63: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:65: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<ipython-input-6-2a4b3666468d>:63: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if self._instrument is \"open\":\n",
            "<ipython-input-6-2a4b3666468d>:65: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if self._instrument is \"close\":\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import glob\n",
        "import numpy as np\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Prices = collections.namedtuple('Prices', field_names=['open', 'high', 'low', 'close', 'volume'])\n",
        "def bar2rel(df,tolerance):\n",
        "    prev_vals = None\n",
        "    fix_open_price  = True\n",
        "    open, high, low, close, volume = [], [], [], [], []\n",
        "    count_out = 0\n",
        "    count_filter = 0\n",
        "    count_fixed = 0\n",
        "    for row in df.itertuples():\n",
        "        val = (row[3],row[4],row[5],row[2],row[1])\n",
        "        po, ph, pl,pc,pv = val\n",
        "        if fix_open_price and prev_vals is not None:\n",
        "            ppo, pph, ppl, ppc, ppv = prev_vals\n",
        "            if abs(po - ppc) > 1e-8:\n",
        "                count_fixed += 1\n",
        "                po = ppc\n",
        "                pl = min(pl, po)\n",
        "                ph = max(ph, po)\n",
        "                count_out += 1\n",
        "        open.append(po)\n",
        "        close.append(pc)\n",
        "        high.append(ph)\n",
        "        low.append(pl)\n",
        "        volume.append(pv)\n",
        "        prev_vals = val\n",
        "    prices=Prices(open=np.array(open, dtype=np.float32),\n",
        "                  high=np.array(high, dtype=np.float32),\n",
        "                  low=np.array(low, dtype=np.float32),\n",
        "                  close=np.array(close, dtype=np.float32),\n",
        "                  volume=np.array(volume, dtype=np.float32))\n",
        "    return prices_to_relative(prices)\n",
        "\n",
        "def prices_to_relative(prices):\n",
        "    \"\"\"\n",
        "    Convert prices to relative in respect to open price\n",
        "    :param ochl: tuple with open, close, high, low\n",
        "    :return: tuple with open, rel_close, rel_high, rel_low\n",
        "    \"\"\"\n",
        "    assert isinstance(prices, Prices)\n",
        "    rh = (prices.high - prices.open) / prices.open\n",
        "    rl = (prices.low - prices.open) / prices.open\n",
        "    rc = (prices.close - prices.open) / prices.open\n",
        "    return Prices(open=prices.open, high=rh, low=rl, close=rc, volume=prices.volume)\n",
        "\n",
        "def preprocess(path):\n",
        "    df = pd.read_csv(os.path.abspath(train_path))\n",
        "\n",
        "    index = [\"open\", \"high\", \"low\",\"close\",\"volume\"]\n",
        "    df[index] = df[index].astype(float)\n",
        "    df_normalized = (df[index] - df[index].min()) / (df[index].max() - df[index].min())\n",
        "    # Define the tolerance value\n",
        "    tolerance = 1e-8\n",
        "\n",
        "    # Apply the lambda function to check if each value is within the tolerance of the first value\n",
        "    df_normalized.applymap(lambda v: abs(v - df_normalized.iloc[0]) < tolerance)\n",
        "    return bar2rel(df_normalized,tolerance)"
      ],
      "metadata": {
        "id": "X_ZcJqVeuvsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"ULTRACEMCO.NS_stock_data.csv\"\n",
        "rp=preprocess(train_path)\n",
        "env  = StocksEnv(rp, bars_count=10,\n",
        "                 commission=0.1,\n",
        "                 reset_on_close=True, state_1d=False,\n",
        "                 random_ofs_on_reset=True, reward_on_close=False,\n",
        "                 volumes=True)\n",
        "obs = env.reset()\n",
        "print(f\"Initial observation: {obs}\")\n",
        "action_idx = env.action_space.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "sCTZgTcZvVID",
        "outputId": "e7815125-0a87-45d9-d0ff-854bada0c271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/ULTRACEMCO.NS_stock_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b06246f4c988>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ULTRACEMCO.NS_stock_data.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m env  = StocksEnv(rp, bars_count=10,\n\u001b[1;32m      4\u001b[0m                  \u001b[0mcommission\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mreset_on_close\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_1d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-233125667fc1>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"open\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"high\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"low\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"volume\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/ULTRACEMCO.NS_stock_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# dataset_path = \"/root/.cache/kagglehub/datasets/nitirajkulkarni/ultracemco-ns-stock-performance/versions/1\"\n",
        "\n",
        "# # List files in the directory\n",
        "# print(os.listdir(dataset_path))\n",
        "\n"
      ],
      "metadata": {
        "id": "DWbUTaxU5n55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "\n",
        "# Get GPU details\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "id": "4MlBHuX7D4BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy torch gym tensorboardX ptan ignite"
      ],
      "metadata": {
        "id": "6vOse0b83f-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Iterable, Union\n",
        "from datetime import datetime, timedelta\n",
        "import ptan\n",
        "import pathlib\n",
        "import argparse\n",
        "import gym.wrappers\n",
        "import torch.optim as optim\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "from tensorboardX import SummaryWriter"
      ],
      "metadata": {
        "id": "CS4V_ZJNFrbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(batch, net, tgt_net, gamma, device=\"cpu\"):\n",
        "    states, actions, rewards, dones, next_states = unpack_batch(batch)\n",
        "    states_v = torch.tensor(states).to(device)\n",
        "    next_states_v = torch.tensor(next_states).to(device)\n",
        "    actions_v = torch.tensor(actions).to(device)\n",
        "    rewards_v = torch.tensor(rewards).to(device)\n",
        "    if dones is not None:\n",
        "        done_mask = torch.BoolTensor(dones.astype(bool)).to(device)\n",
        "    else:\n",
        "        done_mask =torch.BoolTensor(np.array([0],dtype =np.uint8))\n",
        "\n",
        "\n",
        "    state_action_values = net(states_v).gather(1, actions_v.unsqueeze(-1)).squeeze(-1)\n",
        "    # get action performed in next state . i will take max score\n",
        "    next_state_actions = net(next_states_v).max(1)[1]\n",
        "    next_state_values = tgt_net.target_model(next_states_v).gather(1, next_state_actions.unsqueeze(-1)).squeeze(-1)\n",
        "    next_state_values[done_mask] = 0.0\n",
        "    # The Bellman equation is used to compute the expected Q-values for the current state-action pairs.\n",
        "    expected_state_action_values = next_state_values.detach() * gamma + rewards_v\n",
        "    # calculate loss between state_action_values and expected_state_action_values\n",
        "    return nn.MSELoss()(state_action_values, expected_state_action_values)"
      ],
      "metadata": {
        "id": "Decy4Hgo3oid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants and parameters\n",
        "BATCH_SIZE = 32\n",
        "BARS_COUNT = 10\n",
        "EPS_START = 1.0\n",
        "EPS_FINAL = 0.1\n",
        "EPS_STEPS = 1000000\n",
        "GAMMA = 0.99\n",
        "REPLAY_SIZE = 50000\n",
        "REPLAY_INITIAL = 50000\n",
        "REWARD_STEPS = 2\n",
        "LEARNING_RATE = 0.0001\n",
        "STATES_TO_EVALUATE = 1000\n",
        "\n",
        "# Initialize Tensorboard writer\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter(log_dir='logs')\n",
        "\n",
        "METRICS = ('episode_reward', 'episode_steps', 'order_profits', 'order_steps')\n"
      ],
      "metadata": {
        "id": "f2EeugP94ACK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EpsilonTracker:\n",
        "    def __init__(self, selector, eps_start, eps_final, eps_steps):\n",
        "        \"\"\"\n",
        "        Initializes the epsilon tracker to decay epsilon over training steps.\n",
        "\n",
        "        :param selector: The epsilon-greedy action selector.\n",
        "        :param eps_start: Initial epsilon value (high exploration).\n",
        "        :param eps_final: Final epsilon value (low exploration).\n",
        "        :param eps_steps: Number of steps over which epsilon decays.\n",
        "        \"\"\"\n",
        "        self.selector = selector\n",
        "        self.eps_start = eps_start\n",
        "        self.eps_final = eps_final\n",
        "        self.eps_steps = eps_steps\n",
        "        self.epsilon = eps_start  # Start with initial epsilon\n",
        "\n",
        "    def frame(self, frame_idx):\n",
        "        \"\"\"\n",
        "        Updates the epsilon value based on the current training step.\n",
        "\n",
        "        :param frame_idx: The current iteration/frame index.\n",
        "        \"\"\"\n",
        "        # Linearly interpolate epsilon value\n",
        "        self.epsilon = max(self.eps_final, self.eps_start - (frame_idx / self.eps_steps) * (self.eps_start - self.eps_final))\n",
        "        self.selector.epsilon = self.epsilon  # Update epsilon in the action selector\n"
      ],
      "metadata": {
        "id": "ariGbiWtiB57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define batch generator function\n",
        "def batch_generator(buffer: ptan.experience.ExperienceReplayBuffer, initial: int, batch_size: int):\n",
        "    buffer.populate(initial)  # Initially populate buffer\n",
        "    while True:\n",
        "        # Ensure buffer is large enough before sampling\n",
        "        # Change: Only populate if the buffer is not full\n",
        "\n",
        "        yield buffer.sample(batch_size)\n",
        "\n",
        "# Define training batch function\n",
        "def train_batch(engine, batch):\n",
        "    optimizer.zero_grad()\n",
        "    loss_v = calc_loss(batch=batch, net=net, tgt_net=tgt_net, gamma=GAMMA ** REWARD_STEPS, device=device)\n",
        "    loss_v.backward()\n",
        "    optimizer.step()\n",
        "    eps_tracker.frame(engine.state.iteration)\n",
        "    if getattr(engine.state, \"eval_states\", None) is None:\n",
        "        eval_states = buffer.sample(STATES_TO_EVALUATE)\n",
        "        eval_states = [np.array(transition.state, copy=False) for transition in eval_states]\n",
        "        engine.state.eval_states = np.array(eval_states, copy=False)\n",
        "    writer.add_scalar(\"training/loss\", loss_v, engine.state.epoch)\n",
        "    return {\"loss\": loss_v.item(), \"epsilon\": selector.epsilon}\n",
        "\n",
        "# Validation function\n",
        "import tqdm\n",
        "def validation_run(env, net, episodes=100, device=\"cpu\", epsilon=0.02, commission=0.1):\n",
        "    stats = {metric: [] for metric in METRICS}\n",
        "\n",
        "    progress_bar = tqdm.tqdm(range(episodes), desc=\"Validation Progress\", leave=True)\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        obs = env.reset()\n",
        "        while obs is None:\n",
        "            obs = env.reset()\n",
        "        print(f\"Initial observation: {obs}\")\n",
        "        total_reward = 0.0\n",
        "        position = None\n",
        "        position_steps = None\n",
        "        episode_steps = 0\n",
        "\n",
        "        while True:\n",
        "            obs_v = torch.tensor([obs]).to(device)\n",
        "            out_v = net(obs_v)\n",
        "            action_idx = out_v.max(dim=1)[1].item()\n",
        "            if np.random.random() < epsilon:\n",
        "                action_idx = env.action_space.sample()\n",
        "            action = Actions(action_idx)\n",
        "            close_price = env._state._cur_close()\n",
        "\n",
        "            if action == Actions.Buy and position is None:\n",
        "                position = close_price\n",
        "                position_steps = 0\n",
        "            elif action == Actions.Close and position is not None:\n",
        "                profit = close_price - position - (close_price + position) * commission / 100\n",
        "                profit = 100.0 * profit / position\n",
        "                stats['order_profits'].append(profit)\n",
        "                stats['order_steps'].append(position_steps)\n",
        "                position = None\n",
        "                position_steps = None\n",
        "\n",
        "            obs, reward, done, _ = env.step(action_idx)\n",
        "            total_reward += reward\n",
        "            episode_steps += 1\n",
        "            if position_steps is not None:\n",
        "                position_steps += 1\n",
        "            if done:\n",
        "                if position is not None:\n",
        "                    profit = close_price - position - (close_price + position) * commission / 100\n",
        "                    profit = 100.0 * profit / position\n",
        "                    stats['order_profits'].append(profit)\n",
        "                    stats['order_steps'].append(position_steps)\n",
        "                break\n",
        "\n",
        "        stats['episode_reward'].append(total_reward)\n",
        "        stats['episode_steps'].append(episode_steps)\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    return {key: np.mean(vals) for key, vals in stats.items()}"
      ],
      "metadata": {
        "id": "siXGmg8G4rfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import ptan\n",
        "# Assuming rp is your dataset\n",
        "# Split the data into training and validation sets while preserving the Prices namedtuple structure\n",
        "train_indices, val_indices = train_test_split(range(len(rp.open)), test_size=0.20, random_state=42)\n",
        "\n",
        "# Create Prices namedtuples for training and validation sets\n",
        "tp = Prices(open=rp.open[train_indices],\n",
        "            high=rp.high[train_indices],\n",
        "            low=rp.low[train_indices],\n",
        "            close=rp.close[train_indices],\n",
        "            volume=rp.volume[train_indices])\n",
        "\n",
        "vp = Prices(open=rp.open[val_indices],\n",
        "            high=rp.high[val_indices],\n",
        "            low=rp.low[val_indices],\n",
        "            close=rp.close[val_indices],\n",
        "            volume=rp.volume[val_indices])\n",
        "\n",
        "# Creating environments\n",
        "env = StocksEnv(tp, bars_count=10, commission=0.1, reset_on_close=True, state_1d=False, random_ofs_on_reset=True, reward_on_close=False, volumes=True)\n",
        "env_val = StocksEnv(vp, bars_count=10, commission=0.1, reset_on_close=True, state_1d=False, random_ofs_on_reset=True, reward_on_close=False, volumes=True)\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initializing neural network models\n",
        "net = SimpleFFDQN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
        "tgt_net = ptan.agent.TargetNet(net)\n",
        "\n",
        "# Initializing action selector and epsilon tracker\n",
        "selector = ptan.actions.EpsilonGreedyActionSelector(EPS_START)\n",
        "eps_tracker = EpsilonTracker(selector, EPS_START, EPS_FINAL, EPS_STEPS)\n",
        "\n",
        "# Initializing DQN agent\n",
        "agent = ptan.agent.DQNAgent(net, selector, device=device)\n",
        "\n",
        "# Initializing experience source\n",
        "exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, GAMMA, steps_count=REWARD_STEPS)\n",
        "\n",
        "# Initializing optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Initializing Engine for training\n",
        "trainer = Engine(train_batch)"
      ],
      "metadata": {
        "id": "TDZSxx7r4dlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignite event handlers\n",
        "@trainer.on(Events.COMPLETED | Events.EPOCH_COMPLETED(every=10))\n",
        "def log_training_results(engine):\n",
        "    if engine.state.epoch % 10 == 0:\n",
        "        res = validation_run(env_val, net, episodes=100, device=\"cpu\", epsilon=0.02, commission=0.1)\n",
        "        for key, value in res.items():\n",
        "            writer.add_scalar(\"Agent Metrics\", key, value)\n",
        "\n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_something(engine):\n",
        "    out_dict = engine.state.output\n",
        "    for key, value in out_dict.items():\n",
        "        if value is None:\n",
        "            value = 0.0\n",
        "        elif isinstance(value, torch.Tensor):\n",
        "            value = value.item()\n",
        "        writer.add_scalar(f\"Iteration Metrics{engine.state.epoch}/{key}\", value, engine.state.iteration)\n",
        "\n",
        "# Checkpointing\n",
        "checkpoint_handler = ModelCheckpoint(dirname='saved_models', filename_prefix='checkpoint', n_saved=2, require_empty=False)\n",
        "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoint_handler, {'model': net})\n",
        "\n",
        "\n",
        "# Training\n",
        "# from ptan.experience import ExperienceSourceFirstLast\n",
        "# experience_source = ExperienceSourceFirstLast(env, agent, gamma=0.99)\n",
        "buffer = ptan.experience.ExperienceReplayBuffer(experience_source, buffer_size=10000)\n",
        "\n",
        "trainer.run(batch_generator(buffer, REPLAY_INITIAL, BATCH_SIZE), max_epochs=100)\n",
        "writer.close()\n",
        "torch.save(net.state_dict(), 'model_state_dict.pth')\n",
        "res = validation_run(env_val, net, episodes=100, device=\"cpu\", epsilon=0.02, commission=0.1)\n",
        "\n",
        "\n",
        "print(res)"
      ],
      "metadata": {
        "id": "-UJMEVFa4w6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpointing\n",
        "checkpoint_handler = ModelCheckpoint(dirname='saved_models', filename_prefix='checkpoint', n_saved=2, require_empty=False)\n",
        "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpoint_handler, {'model': net})\n",
        "trainer.run(batch_generator(buffer, REPLAY_INITIAL, BATCH_SIZE),max_epochs=100)\n",
        "writer.close()\n",
        "torch.save(net.state_dict(), 'model_state_dict.pth')\n",
        "res=validation_run(env_val, net, episodes=100, device=\"cpu\", epsilon=0.02, comission=0.1)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "kzOkfHLT47B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit pandas numpy scikit-learn joblib\n",
        "pip install torch torchvision  # for PyTorch\n",
        "pip install tensorflow         # for TensorFlow\n"
      ],
      "metadata": {
        "id": "ldAaF8jK4-wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Example: Save a trained model\n",
        "joblib.dump(model, \"model.pkl\")\n"
      ],
      "metadata": {
        "id": "lskUG2zD9SQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = joblib.load(\"model.pkl\")\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"ML Model Deployment with Streamlit\")\n",
        "\n",
        "# User input\n",
        "feature1 = st.number_input(\"Enter Feature 1:\")\n",
        "feature2 = st.number_input(\"Enter Feature 2:\")\n",
        "\n",
        "# Make a prediction\n",
        "if st.button(\"Predict\"):\n",
        "    input_data = np.array([[feature1, feature2]])\n",
        "    prediction = model.predict(input_data)\n",
        "    st.write(f\"Prediction: {prediction[0]}\")\n"
      ],
      "metadata": {
        "id": "nFsYke8x9Wmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run app.py\n"
      ],
      "metadata": {
        "id": "B4m_TdJl9a-q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
